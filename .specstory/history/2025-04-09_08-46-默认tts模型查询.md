<!-- Generated by SpecStory -->

# 默认TTS模型查询 (2025-04-09 16:46:42)

_**User**_

使用的默认TTS模型是哪个啊？

---

_**Assistant**_



---

要确定默认使用的TTS模型，我需要查看项目的配置文件。

1.  **查找配置文件:** 根据 `main/xiaozhi-server/config/settings.py` 文件，默认的配置文件是项目根目录下的 `config.yaml`。
2.  **读取配置文件:** 我将读取 `config.yaml` 文件来查找 `selected_module` 下的 `TTS` 配置项。

我现在来读取 `config.yaml` 文件。

---

Could not find file 'config.yaml'. Did you mean one of:
- main/xiaozhi-server/config.yaml
- main/xiaozhi-server/models/SenseVoiceSmall/config.yaml

---



---

好的，看起来项目根目录下没有 `config.yaml` 文件。工具提示可能的文件是 `main/xiaozhi-server/config.yaml`。

我现在尝试读取 `main/xiaozhi-server/config.yaml` 来查找默认的 TTS 模型设置。

---

Read file: main/xiaozhi-server/config.yaml

---



---

根据 `main/xiaozhi-server/config.yaml` 文件中的配置，默认使用的 TTS 模块是 `EdgeTTS`。

在配置文件的 `selected_module` 部分，可以看到如下设置：

```yaml
selected_module:
  # ... 其他模块 ...
  # TTS将根据配置名称对应的type调用实际的TTS适配器
  TTS: EdgeTTS
  # ... 其他模块 ...
```

这表明系统默认会调用名为 `EdgeTTS` 的配置来处理文本转语音任务。

---

_**User**_

向ws服务器发起请求的数据字段格式是如何的？在哪个文件中定义了规范？

---

_**Assistant**_



---

好的，要了解向 WebSocket 服务器发起请求的数据字段格式以及定义规范的文件，我们需要查看处理 WebSocket 连接的代码。

根据项目结构和之前的上下文，处理连接的核心逻辑很可能在 `main/xiaozhi-server/core/connection.py` 文件中。

我现在来读取 `main/xiaozhi-server/core/connection.py` 文件，分析其中处理接收消息的部分，以确定请求的数据格式。

---

Read file: main/xiaozhi-server/core/connection.py

---



---

从 `main/xiaozhi-server/core/connection.py` 的代码来看，WebSocket 服务器可以接收两种类型的消息：

1.  **文本消息 (String):**
    *   当服务器接收到字符串类型的消息时，会调用 `handleTextMessage` 函数（位于 `main/xiaozhi-server/core/handle/textHandle.py`）来处理。
    *   这些文本消息**通常是 JSON 格式的字符串**，用于发送控制指令、文本查询或其他元数据。具体的字段和结构规范定义在 `main/xiaozhi-server/core/handle/textHandle.py` 中的 `handleTextMessage` 函数及其调用的相关逻辑里。你需要查看该文件以了解详细的字段定义。

2.  **音频消息 (Bytes):**
    *   当服务器接收到字节类型的消息时，会调用 `handleAudioMessage` 函数（位于 `main/xiaozhi-server/core/handle/receiveAudioHandle.py`）来处理。
    *   这些字节消息**是原始的音频数据流**，通常是分块发送的。其格式（如编码、采样率、通道数等）可能在初始连接或特定的文本控制消息中约定。

**总结:**

*   WebSocket 请求的数据格式分为**文本 (JSON 字符串)** 和 **音频 (原始字节流)** 两种。
*   **文本消息的字段规范** 主要在 `main/xiaozhi-server/core/handle/textHandle.py` 中定义和处理。
*   **音频消息的格式**（编码、采样率等）的处理逻辑在 `main/xiaozhi-server/core/handle/receiveAudioHandle.py` 中，具体的格式参数可能通过配置或连接时的消息协商确定。

核心的消息路由逻辑位于 `main/xiaozhi-server/core/connection.py` 的 `_route_message` 方法中。

---

_**User**_

请帮我总结一下，比如音频消息 应该是什么样的请求头？

---

_**Assistant**_



---

好的，总结一下关于 WebSocket 请求头，特别是针对音频消息的部分：

1.  **请求头针对的是初始连接，而非单个音频消息：**
    *   HTTP 风格的请求头（Headers）是在客户端发起**初始 HTTP 请求以升级到 WebSocket 连接**时发送的。
    *   一旦 WebSocket 连接建立成功，后续通过这个连接发送的**单个音频消息（二进制帧）本身不包含独立的 HTTP 请求头**。它们只是纯粹的音频数据字节流。

2.  **初始连接所需的请求头：**
    *   **标准 WebSocket 升级头：** 客户端发起连接时必须包含标准的 WebSocket 协议头，例如：
        *   `Upgrade: websocket`
        *   `Connection: Upgrade`
        *   `Sec-WebSocket-Key`: 客户端生成的随机密钥。
        *   `Sec-WebSocket-Version`: 通常是 `13`。
    *   **认证头 (根据配置)：** 在 `main/xiaozhi-server/core/connection.py` 的 `handle_connection` 方法中，调用了 `self.auth.authenticate(self.headers)`。这意味着初始连接需要包含认证信息。根据 `config.yaml` 中 `server.auth` 的配置：
        *   如果 `enabled: true`，则需要根据 `core/auth.py` 的实现提供认证头。这通常是 `Authorization` 头（例如 `Authorization: Bearer your-token1`）或者配置文件中定义的其他自定义头来传递 `tokens` 列表中的某个 token。
    *   **设备 ID 头 (可选，用于私有配置)：** 代码中检查了 `self.headers.get("device-id", None)`。如果你的服务端配置了 `use_private_config: true` 并且你想为特定设备加载私有配置，那么初始连接的请求头中**需要包含 `device-id` 头**，其值为设备的唯一标识符（例如 MAC 地址或其他 ID）。

**总结:**

发送**音频消息本身**（即 `handleAudioMessage` 函数处理的 `bytes` 数据）时，你不需要为每一块音频数据附加请求头。你需要确保在**建立 WebSocket 连接的初始 HTTP 请求**中包含了所有必需的头信息（标准的 WebSocket 头、认证头、以及可选的 `device-id` 头）。音频数据的格式（如 Opus 编码、16000Hz 采样率等）是在配置 (`config.yaml` 的 `xiaozhi.audio_params`) 中定义的，服务器会按照这个约定来解析接收到的音频字节流。

---

_**User**_

config.yaml 的 xiaozhi.audio_params 是在哪个函数中处理的？

---

_**Assistant**_



---

`config.yaml` 文件中的 `xiaozhi.audio_params` 定义了客户端通过 WebSocket 发送过来的音频流的预期格式参数（如编码、采样率、通道数、帧时长）。

这些参数主要由处理**接收到的音频数据**的模块使用，特别是：

1.  **VAD (Voice Activity Detection) 模块:** VAD 需要知道音频的采样率 (`sample_rate`) 和可能的帧时长 (`frame_duration`) 来准确地检测语音活动。例如，`SileroVAD` 在处理音频块时需要这些信息。
2.  **ASR (Automatic Speech Recognition) 模块:** ASR 模型（如 `FunASR`, `SherpaASR` 等）需要知道输入音频的采样率 (`sample_rate`)、通道数 (`channels`) 和编码格式 (`format`) 才能正确地将语音转换成文本。

**处理流程:**

1.  **加载配置:** 服务器启动时（很可能在 `server.py` 或类似的主入口文件中），会加载 `config.yaml` 文件。
2.  **初始化组件:** 在创建 VAD 和 ASR 实例时，会将 `config` 中的相关参数（包括 `xiaozhi.audio_params` 或其子集，特别是 `sample_rate`）传递给这些组件的构造函数 (`__init__`) 或初始化方法。
3.  **音频处理:**
    *   在 `main/xiaozhi-server/core/handle/receiveAudioHandle.py` 中的 `handleAudioMessage` 函数接收到原始音频字节流 (`message`)。
    *   这些字节流会传递给 VAD 实例 (`self_.vad.is_speech(message)`) 进行处理。VAD 内部会使用之前初始化时获取的 `sample_rate` 等参数。
    *   识别出的语音片段会传递给 ASR 实例 (`self_.asr.transcribe(audio_chunk)`)。ASR 内部同样会使用初始化时获取的音频参数来执行识别。

虽然 `ConnectionHandler` (`main/xiaozhi-server/core/connection.py`) 持有整个 `config` 对象，但它本身并不直接使用 `xiaozhi.audio_params`。这些参数是在 VAD 和 ASR 组件**内部**被实际使用的，通常是在它们的**初始化阶段**接收这些配置，并在后续的音频处理函数中应用。

你需要查看你所选择的 VAD 和 ASR 实现类的具体代码（例如 `vad/silero_vad.py` 或 `asr/funasr_asr.py` 等）以及服务器主入口文件（可能是 `server.py`）中初始化这些类的部分，来找到 `audio_params` 被直接读取和使用的确切位置。

---

_**User**_

哪个函数用来接收客户端的音频内容？

---

_**Assistant**_



---

接收客户端音频内容的函数是 `handleAudioMessage`。

在 `main/xiaozhi-server/core/connection.py` 文件中，`_route_message` 方法负责根据消息类型进行路由：

```python
async def _route_message(self, message):
    """消息路由"""
    if isinstance(message, str):
        await handleTextMessage(self, message) # 处理文本消息
    elif isinstance(message, bytes):
        await handleAudioMessage(self, message) # 处理音频消息 (bytes类型)
```

当 WebSocket 连接收到 `bytes` 类型的消息时，`_route_message` 会调用 `handleAudioMessage` 函数来处理这些音频数据。

`handleAudioMessage` 函数本身定义在 `main/xiaozhi-server/core/handle/receiveAudioHandle.py` 文件中。

---

_**User**_

@config.yaml  为什么我保存后，格式被自动修改了？就出现了如上的错误？

---

_**Assistant**_



---

这个 `yaml.scanner.ScannerError` 错误，特别是 `could not find expected ':'` 并指向 `line 588, column 7`，几乎总是由 **YAML 文件缩进错误** 引起的。

正如你提到的“格式被自动修改了”，这很可能是问题的根源：

1.  **YAML 的缩进敏感性：** YAML 语言使用缩进来定义层级结构。父子关系、列表项等都依赖于精确的空格缩进（通常是 2 个或 4 个空格，不能混用 Tab 和空格）。
2.  **自动格式化工具的问题：** 当你保存文件时，你的编辑器或 IDE 可能配置了自动格式化工具（例如 Prettier 或其他代码美化插件）。有时，这些工具可能没有正确配置 YAML 文件的格式化规则，或者在处理复杂的注释、多行字符串时出错，导致它们**错误地修改了文件的缩进**。
3.  **错误分析：**
    *   错误信息 `while scanning a simple key` 和 `could not find expected ':'` 表明解析器在尝试读取一个键值对时，在期望找到冒号 `:` 的地方遇到了问题。
    *   指向 `line 588, column 7` 意味着问题发生在 `TTS302AI:` (这可能是第 587 行) 下方的某一行。很可能是自动格式化工具将第 588 行（可能是 `# 302AI语音合成服务...` 这行注释，或者 `type: doubao` 这一行）的缩进改错了，使其不再被视为 `TTS302AI` 的子项，或者缩进层级混乱，导致解析器无法理解文件结构。

**如何解决：**

1.  **检查缩进：** 手动检查 `config.yaml` 文件中第 587 行 (`TTS302AI:`) 及其后面几行（直到下一个同级或更高级别的键）的缩进。确保：
    *   `TTS302AI:` 下面的所有配置项（如 `type`, `api_url`, `authorization` 等）都比 `TTS302AI` 多一层固定的空格缩进（通常是 2 个空格）。
    *   整个文件中使用的缩进是统一的（全是空格，不要混用 Tab）。
2.  **暂时禁用自动格式化：** 在你的编辑器/IDE 设置中，暂时禁用针对 `.yaml` 文件的保存时自动格式化功能，然后手动修复缩进错误并保存，看看问题是否解决。
3.  **配置或更换格式化工具：** 如果确实是格式化工具的问题，检查其配置是否适用于 YAML，或者考虑更换一个对 YAML 支持更好的格式化工具或 Linter。
4.  **使用 YAML 验证器：** 可以将你的 `config.yaml` 内容复制到在线的 YAML 验证器中，它通常能更精确地指出语法错误的位置。

最可能的情况是自动格式化工具破坏了 `TTS302AI:` 下方某行的缩进。请仔细检查该区域的空格。

---



---

